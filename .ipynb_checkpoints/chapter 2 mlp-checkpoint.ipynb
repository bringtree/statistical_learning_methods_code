{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "pwd = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onehot编码可以用 np.eye 来快速生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(labels):\n",
    "  labels = labels.astype(int)\n",
    "  onehot_labels = np.eye(labels.shape[0], 31)[labels]\n",
    "  return onehot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果序列长度不同 可以用keras 的pad_sequences 来填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(x_src, y_src):\n",
    "  x = np.load(x_src)\n",
    "  # x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=20, dtype='float32',\n",
    "  #                                                   padding='post', truncating='post', value=0.)\n",
    "  #   nsamples, nx = x.shape\n",
    "  # x = x.reshape((nsamples, nx))\n",
    "\n",
    "  y = np.load(y_src)\n",
    "  y = onehot(y)\n",
    "\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率\n",
    "def compute_accurate_rate(x_dev, y_dev):\n",
    "  num = x_dev.shape[0]\n",
    "  total_batch = int(num / batch_size)\n",
    "  score = 0\n",
    "  for i in range(total_batch):\n",
    "    correct_prediction = tf.equal(tf.argmax(out_layer, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    score2 = accuracy.eval(\n",
    "      {x: x_dev[i * batch_size:batch_size * (i + 1)], y: y_dev[i * batch_size:batch_size * (i + 1)]})\n",
    "    score += score2\n",
    "\n",
    "  return score / total_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 2675\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 5000\n",
    "batch_size = 75\n",
    "# 要调的layer大小\n",
    "hidden_layer_sizes = [[512, 256], [256, 128], [256, 64], [128, 64]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " tf.reset_default_graph() 是为了清除前面的计算图，会把之前的变量这些都清了<br>\n",
    " hparam_str 是为了拼接字符串，然后输出的tensorboard的时候好看，能对比区别<br>\n",
    " Variable 和get_variable(不记得是不是这样拼了，没代码补充提示)，前面的是直接创建，后面的是回去搜索一遍不重复(前提:name_scope的reuse=True的话,不是就直接创建)<br>\n",
    " tf.summary.scalar 添加向量到 summary中<br>\n",
    " merged_summary = tf.summary.merge_all() 把添加的向量全部集合起来<br>\n",
    " 然后sess.run的时候run吧merged_summary也run一下。<br>\n",
    " 并且把输出ms到writer.add_summary(ms, epoch)<br>\n",
    " writer 是 writer = tf.summary.FileWriter(\"/home/bringtree/data/mlp_demo/\" + hparam_str)<br>\n",
    " 添加操作图writer.add_graph(sess.graph)<br>\n",
    " \n",
    " 会遇到的问题:<br>\n",
    " 1. 如下面的情况 有时候 会用留1法等等来训练超参，这时候writer会出现覆盖的现象，记得改文件名,清graph.<br>\n",
    " 2. 不同色文件名 颜色不同 不能自定义<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in hidden_layer_sizes:\n",
    "  tf.reset_default_graph()\n",
    "  hparam_str = \"cell_\" + str(cell[0]) + '_' + str(cell[1])\n",
    "\n",
    "  x = tf.placeholder('float32', [batch_size, input_shape], name=\"x\")\n",
    "  y = tf.placeholder('float32', [batch_size, 31], name=\"labels\")\n",
    "  with tf.name_scope(\"input_layer\"):\n",
    "    w_1 = tf.Variable(tf.random_uniform([input_shape, cell[0]], dtype='float32'), name=\"w_1\")\n",
    "    b_1 = tf.Variable(tf.random_uniform([cell[0]], dtype='float32'), name=\"b_1\")\n",
    "    layer1 = tf.matmul(x, w_1)\n",
    "    layer1 = tf.add(layer1, b_1)\n",
    "    layer1 = tf.contrib.layers.batch_norm(layer1, decay=0.9, updates_collections=None, epsilon=1e-5, scale=True)\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "\n",
    "  with tf.name_scope(\"mid_layer\"):\n",
    "    w_2 = tf.Variable(tf.random_uniform([cell[0], cell[1]], dtype='float32'), name=\"w_2\")\n",
    "    b_2 = tf.Variable(tf.random_uniform([cell[1]], dtype='float32'), name=\"b_2\")\n",
    "    layer2 = tf.matmul(layer1, w_2)\n",
    "    layer2 = tf.add(layer2, b_2)\n",
    "    layer2 = tf.contrib.layers.batch_norm(layer2, decay=0.9, updates_collections=None, epsilon=1e-5, scale=True)\n",
    "    layer3 = tf.nn.relu(layer2)\n",
    "\n",
    "  with tf.name_scope(\"output_layer\"):\n",
    "    w_3 = tf.Variable(tf.random_uniform([cell[1], 31], dtype='float32'), name=\"w_3\")\n",
    "    b_3 = tf.Variable(tf.random_uniform([31], dtype='float32'), name=\"b_3\")\n",
    "    out_layer = tf.add(tf.matmul(layer3, w_3), b_3)\n",
    "\n",
    "  with tf.name_scope(\"lost_function\"):\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=out_layer))\n",
    "\n",
    "  with tf.name_scope(\"train_optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "  # 训练模型\n",
    "  model_accuracy = 0\n",
    "  for data_index in range(1, 5):\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "      correct_prediction = tf.equal(tf.argmax(out_layer, 1), tf.argmax(y, 1))\n",
    "      accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "      tf.summary.scalar('accuracy' + str(data_index), accuracy)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "      writer = tf.summary.FileWriter(\"/home/bringtree/data/mlp_demo/\" + hparam_str)\n",
    "      writer.add_graph(sess.graph)\n",
    "      init = tf.global_variables_initializer()\n",
    "      sess.run(init)\n",
    "      merged_summary = tf.summary.merge_all()\n",
    "\n",
    "      for epoch in range(1, training_epochs + 1):\n",
    "        x_train, y_train = read_data(\n",
    "          pwd + \"/SMP2017/smp2017_5fold/\" + str(data_index) + \"_train_test_x_train_kf_smp_bow.npy\",\n",
    "          pwd + \"/SMP2017/smp2017_5fold/\" + str(data_index) + \"_train_test_y_train_kf_smp_bow.npy\")\n",
    "\n",
    "        avg_cost = 0\n",
    "        n_sample = x_train.shape[0]\n",
    "        total_batch = int(n_sample / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "          _, c = sess.run([optimizer, cost], feed_dict={x: x_train[i * batch_size: (i + 1) * batch_size],\n",
    "                                                        y: y_train[i * batch_size: (i + 1) * batch_size]})\n",
    "          avg_cost += c / total_batch\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "          # accurate_rate\n",
    "          x_dev, y_dev = read_data(\n",
    "            pwd + \"/SMP2017/smp2017_5fold/\" + str(data_index) + \"_train_test_x_test_kf_smp_bow.npy\",\n",
    "            pwd + \"/SMP2017/smp2017_5fold/\" + str(data_index) + \"_train_test_y_test_kf_smp_bow.npy\")\n",
    "\n",
    "          num = x_dev.shape[0]\n",
    "          total_batch = int(num / batch_size)\n",
    "          score = 0\n",
    "          for i in range(total_batch):\n",
    "            score2, ms = sess.run([accuracy, merged_summary],\n",
    "                                  feed_dict={x: x_dev[i * batch_size:batch_size * (i + 1)],\n",
    "                                             y: y_dev[i * batch_size:batch_size * (i + 1)]})\n",
    "            score += score2\n",
    "          writer.add_summary(ms, epoch)\n",
    "\n",
    "          accuracy_average = score / total_batch\n",
    "\n",
    "          # print('Epoch:', '%04d' % (epoch), \"Accuracy:\" + str(accuracy_average))\n",
    "          # print('Epoch:', '%04d' % (epoch), 'cost=', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "      x_dev, y_dev = read_data(\n",
    "        pwd + \"/SMP2017/smp2017_5fold/\" + str(data_index) + \"_train_test_x_test_kf_smp_bow.npy\",\n",
    "        pwd + \"/SMP2017/smp2017_5fold/\" + str(data_index) + \"_train_test_y_test_kf_smp_bow.npy\")\n",
    "      model_accuracy += compute_accurate_rate(x_dev, y_dev)\n",
    "\n",
    "  print(str(model_accuracy / 4) + ',' + str(cell) + ',' + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
